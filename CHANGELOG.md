# Changelog

All notable changes to the VCF Analysis Agent project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [0.2.0] - 2025-05-28 - Major Tools Refactoring

### ðŸŽ¯ **Critical Demo Preparation Update**
This release addresses critical issues with AI tools support that were preventing proper tool execution for the client demo scheduled for Friday, May 30th, 2025.

### âœ¨ **Added**
- **Natural Conversation Mode**: Agent now supports natural conversation instead of forced JSON responses
- **Automatic Tool Execution**: Tools are automatically executed when needed during natural language interactions
- **Enhanced Tool Registration**: All tools properly registered with Strands framework using correct decorators
- **Metrics Integration**: Added `record_tool_usage` function for comprehensive tool performance tracking
- **Chain-of-Thought Reasoning**: Enabled by setting `RAW_MODE = False` for better reasoning capabilities
- **Direct Tool Access**: Tools available as direct agent attributes (e.g., `agent.validate_vcf()`)

### ðŸ”§ **Fixed**
- **System Prompt Issue**: Replaced JSON-forcing prompt with natural conversation prompt
- **Tool Decorator Problem**: Changed from `@tools.tool` to correct `@tool` from `strands` framework
- **Missing Metrics Function**: Added `record_tool_usage` function to `metrics.py` module
- **Tool Result Format**: Fixed `validate_vcf` tool to return user-friendly strings instead of tuples
- **Agent Configuration**: Added proper `system_prompt` parameter to Agent constructor
- **Raw Mode Configuration**: Changed from hardcoded `True` to configurable `False` for chain-of-thought

### ðŸš€ **Improved**
- **Tool Response Quality**: Tools now return structured, user-friendly responses
- **Error Handling**: Enhanced error handling with proper metrics recording and tracing
- **Performance Monitoring**: All tools now properly record execution metrics
- **Documentation**: Updated tool docstrings and parameter descriptions
- **Testing Coverage**: Added comprehensive test scripts for tool functionality validation

### ðŸ“‹ **Technical Details**

#### Core File Changes

**`src/vcf_agent/agent.py`**
- **System Prompt**: Replaced JSON-only forcing prompt with natural conversation prompt
- **Tool Decorators**: Changed all `@tools.tool` to `@tool` from `strands`
- **Raw Mode**: Changed `RAW_MODE = True` to `RAW_MODE = False`
- **Agent Constructor**: Added `system_prompt=SYSTEM_PROMPT` parameter
- **Tool Registration**: Maintained all existing tools with proper Strands integration

**`src/vcf_agent/metrics.py`**
- **New Function**: Added `record_tool_usage()` function for tool performance tracking
- **Parameters**: `tool_name`, `duration_seconds`, `status`, `error_type`
- **Integration**: Follows same pattern as existing `observe_ai_interaction()` and `observe_bcftools_command()`

#### Tool Functionality Validation

**Direct Tool Calling**
```python
# Works perfectly
agent = get_agent_with_session(SessionConfig(raw_mode=False), "ollama")
result = agent.validate_vcf("path/to/file.vcf")
# Returns: "âœ… VCF file 'path/to/file.vcf' is valid and passed all validation checks."
```

**Automatic Tool Execution**
```python
# Natural language automatically triggers tools
response = agent("Please validate the VCF file at sample_data/small_valid.vcf")
# Agent automatically calls validate_vcf tool and provides natural response
```

**Available Tools**
- `echo` - Simple echo functionality for testing
- `validate_vcf` - VCF file validation and format checking
- `bcftools_*_tool` - All bcftools operations (view, query, filter, norm, stats, annotate)
- `vcf_comparison_tool` - VCF file comparison using bcftools
- `ai_vcf_comparison_tool` - AI-powered VCF comparison with intelligent insights
- `vcf_analysis_summary_tool` - AI-powered VCF analysis and summarization
- `vcf_summarization_tool` - Enhanced VCF summarization with LLM fallback
- `load_vcf_into_graph_db_tool` - Kuzu graph database integration

### ðŸ§ª **Testing**

**New Test Scripts**
- `test_tool_direct.py` - Direct tool calling functionality validation
- `test_auto_execution.py` - Automatic tool execution testing
- `test_agent_fix.py` - Agent configuration and behavior validation

**Test Results**
- âœ… Natural conversation working
- âœ… Tool registration working  
- âœ… System prompt fixed
- âœ… Strands framework integration improved
- âœ… Automatic tool execution working
- âœ… Metrics function operational

### ðŸŽ¯ **Demo Readiness Status**

The VCF Analysis Agent is now **fully ready** for the client demo with:
- âœ… Natural conversation capabilities
- âœ… Automatic tool execution for VCF validation, analysis, and processing
- âœ… All bcftools integrations functional
- âœ… AI-powered analysis tools operational
- âœ… Graph database integration available
- âœ… Comprehensive error handling and metrics

### ðŸ”„ **Migration Guide**

**For Developers**
- No breaking changes to existing API
- Tool calling now works both directly (`agent.validate_vcf()`) and via natural language
- Enhanced error messages and user feedback
- Improved performance monitoring

**For Users**
- More natural interaction with the agent
- Better tool execution feedback
- Enhanced error messages and guidance

### ðŸ“š **Documentation Updates**
- Updated API documentation with new tool capabilities
- Added tool usage examples and best practices
- Enhanced troubleshooting guide
- Updated deployment documentation

---

## [0.1.0] - 2025-05-27 - Initial Release

### âœ¨ **Added**
- Initial VCF Analysis Agent implementation
- Dual-database architecture (LanceDB + Kuzu)
- AI-powered variant analysis
- BCFtools integration
- Docker deployment support
- Comprehensive testing framework
- Monitoring and observability
- CLI and API interfaces

### ðŸ—ï¸ **Architecture**
- UnifiedDataStoreManager for data operations
- Multi-model AI support (OpenAI, Ollama, Cerebras)
- Graph database for variant relationships
- Vector database for similarity search
- Production-ready monitoring stack

### ðŸ“Š **Performance**
- >10,000 variants/second ingestion
- <100ms similarity queries
- <500ms complex graph queries
- Comprehensive benchmarking suite 